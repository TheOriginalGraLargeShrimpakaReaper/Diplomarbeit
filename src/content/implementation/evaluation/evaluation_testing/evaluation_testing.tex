%! Author = gramic
%! Date = 08.04.24

% Preamble
\begin{flushleft}
    \subsection{Testing Evaluationssysteme}
    %\input{content/implementation/evaluation/evaluation_testing/evaluation_testcases}
    %\input{content/implementation/evaluation/evaluation_testing/yugabyteDB}
    \subsubsection{Patroni}
    Patroni funktionierte wie gewollt.\\
    Da kein Connection Pooler auf dem Proxy-Host installiert wurde, kam nicht alles erfüllt werden.\\
    Wichtig dazu ist zu sagen, dass die REST-API und das Command vollständig funktioniert.\\
    Ein Switchover wurde mit folgendem Command ausgeführt:
\lstset{style=gra_codestyle}
\begin{lstlisting}[language=bash, caption=Patroni - Testing - Switchover,captionpos=b,label={lst:testing_patroni_switchover},breaklines=true]
root@sks1234:~# patronictl -c /etc/patroni/config.yml switchover
Current cluster topology
+ Cluster: postgres (7357340759952276373) +-----------+----+-----------+
| Member     | Host        | Role         | State     | TL | Lag in MB |
+------------+-------------+--------------+-----------+----+-----------+
| postgres01 | 10.0.20.110 | Leader       | running   |  3 |           |
| postgres02 | 10.0.20.111 | Sync Standby | streaming |  3 |         0 |
| postgres03 | 10.0.20.112 | Sync Standby | streaming |  3 |         0 |
+------------+-------------+--------------+-----------+----+-----------+
Primary [postgres01]:
Candidate ['postgres02', 'postgres03'] []: postgres02
When should the switchover take place (e.g. 2024-04-26T16:08 )  [now]: now
Are you sure you want to switchover cluster postgres, demoting current leader postgres01? [y/N]: y
2024-04-26 15:09:02.68997 Successfully switched over to "postgres02"
+ Cluster: postgres (7357340759952276373) -----+----+-----------+
| Member     | Host        | Role    | State   | TL | Lag in MB |
+------------+-------------+---------+---------+----+-----------+
| postgres01 | 10.0.20.110 | Replica | stopped |    |   unknown |
| postgres02 | 10.0.20.111 | Leader  | running |  3 |           |
| postgres03 | 10.0.20.112 | Replica | running |  3 |         0 |
+------------+-------------+---------+---------+----+-----------+
\end{lstlisting}
    Ein gestoppter Node wurde wie folgt wieder neu aufgebaut:
\lstset{style=gra_codestyle}
\begin{lstlisting}[language=bash, caption=Patroni - Testing - Reinit,captionpos=b,label={lst:testing_patroni_reinit},breaklines=true]
root@sks1234:~# patronictl -c /etc/patroni/config.yml reinit postgres
+ Cluster: postgres (7357340759952276373) +-----------+----+-----------+
| Member     | Host        | Role         | State     | TL | Lag in MB |
+------------+-------------+--------------+-----------+----+-----------+
| postgres01 | 10.0.20.110 | Sync Standby | streaming |  4 |         0 |
| postgres02 | 10.0.20.111 | Leader       | running   |  4 |           |
| postgres03 | 10.0.20.112 | Sync Standby | streaming |  4 |         0 |
+------------+-------------+--------------+-----------+----+-----------+
Which member do you want to reinitialize [postgres03, postgres01]? []: postgres01
Are you sure you want to reinitialize members postgres01? [y/N]: y
Success: reinitialize for member postgres01
\end{lstlisting}
    Das vollständige Ergebnis:
    \input{content/latex_tables/evaluation_tests_patroni}
\end{flushleft}
\begin{flushleft}
    \subsubsection{StackGres -Citus}
    StackGres kann nicht alle Anforderungen erfüllen.\\
    Obwohl es mit \texttt{envoy} und \texttt{pgBouncer} einen Proxy und einen Connection Pooler gibt,\\
    scheint dies nicht über die Coordinator-Nodes selbst zu gehen.\\
    Daher brechen bestehende Connections ab oder laufen irgendwann in ein Timeout, wenn \Gls{Kubernetes} Nodes nicht schnell genug heruntergefahren werden.
\end{flushleft}
\begin{flushleft}
    Aufgrund des Sharding und das in sich geschlossenen \Gls{Kubernetes}-Environments wurde auf separate Tablespaces verzichtet.
\end{flushleft}
\begin{flushleft}
    Zuerst wurde versucht, das Sharding mit Version 12 eingeführte Schema Based Sharding umzusetzen.\\
    Wie beim Benchmarking auch, zeigten sich schnell die Grenzen des Citrus-Sharding.\\
    Sobald ein Foreign-Key zwischen zwei Tabellen, die in verschiedenen Schemas liegen, existiert, kann kein Schema Based Sharding mehr ausgeführt werden.\\
    Auch hier besteht die Lösung darin, Reference Tables zu erstellen.
\end{flushleft}
\begin{flushleft}
    \input{content/latex_tables/evaluation_tests_stackgres_citus}
    Die genauen Details sind im \hyperref[subsec:appendix_testing_stackgres_citus]{Anhang - StackGres - Citus Testing} zu finden.
\end{flushleft}
\begin{flushleft}
    \subsubsection{YugabyteDB}
    YugabyteDB funktionierte so weit:\\
    \input{content/latex_tables/evaluation_tests_yugabytedb}
    Was es aber bei einer Testinstallation zu prüfen gilt, ist die Zeiteinstellung.
\end{flushleft}
\begin{flushleft}
    Während des Testing kam es immer wieder vor, dass ein Node Probleme mit der Zeit bekam.\\
    Dies fiel immer dann auf, wenn ein Node (meistens \texttt{sks1184}), heruntergefahren und später rebooted wurde.\\
    Der Fehler trat auch erst auf, als die Nodes aus einem Grund aus einem Snapshot wiederhergestellt werden mussten.\\
    YugabyteDB stellt dann oft mehr als 500ms Zeitunterschied zwischen dem Tablet-Leader und dem Follower fest.\\
    Sobald dies zutritt, ist der Server Node nicht mehr arbeitsfähig, da die Zeit für die Synchronisation der Daten benötigt wird\cite{BYH9Z3MS}.\\
    Oft kam auch die Meldung, dass \texttt{chronyc} nicht mehr auf dem Pod installiert sei.\\
    Auf dem Servern scheinen die Zeiten aber synchron zu sein, eine genaue Ursache konnte nicht gefunden werden.\\
    Eine mögliche Ursache ist eine unsaubere Konfiguration von \gls{rke2}.
\end{flushleft}
\begin{flushleft}
    Der Beschrieb, wie sich der Fehler dann äussert, ist hier im \hyperref[subsec:appendix_testing_yugabytedb]{Anhang - YugabyteDB Testing} zu finden.
\end{flushleft}